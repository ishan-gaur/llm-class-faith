{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from config import api_key\n",
    "from utils import load_dataset, create_dataset\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "results_path = Path.cwd() / \"results\"\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'all_lower': 67,\n",
      " 'all_upper': 59,\n",
      " 'city': 25,\n",
      " 'even_words': 97,\n",
      " 'fragment_subject': 20,\n",
      " 'fragment_verb': 20,\n",
      " 'gpt4': 200,\n",
      " 'nature': 62,\n",
      " 'odd_words': 103,\n",
      " 'proper_noun': 32,\n",
      " 'sentence': 160,\n",
      " 'shared_sample': 42,\n",
      " 'start_cap': 133,\n",
      " 'start_lower': 67,\n",
      " 'start_the': 57}\n"
     ]
    }
   ],
   "source": [
    "dataset, tag_counts = load_dataset(\"capital.json\")\n",
    "print(len(dataset))\n",
    "pprint(tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets: all upper vs lower; starts with a capital vs not; has a capital vs not\n",
    "# even vs odd counts; even vs odd length w/ all upper vs lower-->even mixed, odd mixed\n",
    "# fragments vs sentence; just subject/verb fragments vs all\n",
    "# nature vs rest\n",
    "# contains a proper noun\n",
    "tags_true = [\"all_upper\"]\n",
    "tags_false = [\"all_lower\"]\n",
    "tags_common = [\"sentence\"]\n",
    "positives, negatives = create_dataset(dataset, tags_true, tags_false, tags_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input': 'THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'start_the',\n",
      "           'gpt4']},\n",
      " {'input': 'TODAY IS A BEAUTIFUL DAY.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'odd_words',\n",
      "           'gpt4']},\n",
      " {'input': 'I LOVE TO TRAVEL AND EXPLORE NEW PLACES.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'PYTHON IS A POPULAR PROGRAMMING LANGUAGE.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'even_words',\n",
      "           'gpt4',\n",
      "           'proper_noun']},\n",
      " {'input': 'THE SUN SETS IN THE WEST.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'start_the',\n",
      "           'gpt4']},\n",
      " {'input': 'HAPPINESS IS A WARM CUP OF TEA.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'odd_words',\n",
      "           'gpt4']},\n",
      " {'input': 'THE MOONLIGHT CASTS A GLOW OVER THE NIGHT.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'start_the',\n",
      "           'gpt4']},\n",
      " {'input': 'WINTER BRINGS SNOW AND FROSTY MORNINGS.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'MUSIC HAS THE POWER TO EVOKE STRONG EMOTIONS.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'SCIENCE AND TECHNOLOGY ARE DRIVING INNOVATION.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'FRIENDSHIP IS LIKE A SHINING STAR IN THE DARK.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'odd_words',\n",
      "           'gpt4']},\n",
      " {'input': 'THE OCEAN WAVES CRASH AGAINST THE SHORE.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'start_the',\n",
      "           'gpt4']},\n",
      " {'input': 'READING OPENS DOORS TO NEW WORLDS.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'COFFEE IS THE FUEL OF PRODUCTIVITY.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'DREAM BIG AND WORK HARD TO ACHIEVE IT.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'THE EARTH ROTATES ON ITS AXIS.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'start_the',\n",
      "           'gpt4',\n",
      "           'proper_noun']},\n",
      " {'input': 'SUCCESS IS A JOURNEY, NOT A DESTINATION.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'odd_words',\n",
      "           'gpt4']},\n",
      " {'input': 'HEALTHY HABITS LEAD TO A HAPPY LIFE.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'odd_words',\n",
      "           'gpt4']},\n",
      " {'input': 'THE STARS TWINKLE IN THE NIGHT SKY.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'start_the',\n",
      "           'gpt4']},\n",
      " {'input': 'ALWAYS STRIVE FOR EXCELLENCE.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'THE MOUNTAINS ARE MAJESTIC AND GRAND.',\n",
      "  'tags': ['start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'shared_sample',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'start_the',\n",
      "           'gpt4']},\n",
      " {'input': 'CHANGE IS THE ONLY CONSTANT.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'LEARNING IS A LIFELONG JOURNEY.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'CURIOSITY LEADS TO DISCOVERY.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'even_words', 'gpt4']},\n",
      " {'input': 'GRATITUDE OPENS DOORS TO ABUNDANCE.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': \"TIME FLIES WHEN YOU'RE HAVING FUN.\",\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'even_words', 'gpt4']},\n",
      " {'input': 'THE UNIVERSE IS VAST AND MYSTERIOUS.',\n",
      "  'tags': ['start_the',\n",
      "           'start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'PATIENCE IS A VIRTUE.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'even_words', 'gpt4']},\n",
      " {'input': 'LOVE CONQUERS ALL.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'THE WIND WHISPERS THROUGH THE TREES.',\n",
      "  'tags': ['start_the',\n",
      "           'start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'CHOCOLATE IS A DELIGHTFUL INDULGENCE.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'THE SUNRISE PAINTS THE SKY WITH WARM COLORS.',\n",
      "  'tags': ['start_the',\n",
      "           'start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'FAILURE IS A STEPPING STONE TO SUCCESS.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'POSITIVITY BREEDS POSITIVITY.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'THE EAGLE SOARS HIGH IN THE SKY.',\n",
      "  'tags': ['start_the',\n",
      "           'start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'gpt4']},\n",
      " {'input': 'PEACE BEGINS WITH A SMILE.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'THE RAINBOW BRINGS JOY AFTER THE RAIN.',\n",
      "  'tags': ['start_the',\n",
      "           'start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'gpt4']},\n",
      " {'input': 'KNOWLEDGE IS POWER.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'FAMILY HOLDS A SPECIAL PLACE IN OUR HEARTS.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'even_words', 'gpt4']},\n",
      " {'input': 'THE FLOWERS BLOOM IN SPRING.',\n",
      "  'tags': ['start_the',\n",
      "           'start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'gpt4']},\n",
      " {'input': 'LAUGHTER IS THE BEST MEDICINE.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'BE KIND TO ONE ANOTHER.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'THE OLYMPICS CELEBRATE ATHLETIC EXCELLENCE.',\n",
      "  'tags': ['start_the',\n",
      "           'start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'odd_words',\n",
      "           'gpt4',\n",
      "           'proper_noun']},\n",
      " {'input': \"LIFE IS WHAT HAPPENS WHEN YOU'RE BUSY MAKING PLANS.\",\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'COURAGE IS RESISTANCE TO FEAR, MASTERY OF FEAR, NOT ABSENCE OF '\n",
      "           'FEAR.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'even_words', 'gpt4']},\n",
      " {'input': 'THE SILENCE OF NATURE IS VERY REAL. IT SURROUNDS YOU...',\n",
      "  'tags': ['start_the',\n",
      "           'start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'even_words',\n",
      "           'gpt4']},\n",
      " {'input': 'A SUCCESSFUL MAN IS ONE WHO CAN LAY A FIRM FOUNDATION WITH THE '\n",
      "           'BRICKS OTHERS HAVE THROWN AT HIM.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'odd_words', 'gpt4']},\n",
      " {'input': 'IN THE END, WE WILL REMEMBER NOT THE WORDS OF OUR ENEMIES, BUT THE '\n",
      "           'SILENCE OF OUR FRIENDS.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'even_words', 'gpt4']},\n",
      " {'input': 'THERE IS NOTHING EITHER GOOD OR BAD, BUT THINKING MAKES IT SO.',\n",
      "  'tags': ['start_cap', 'all_upper', 'sentence', 'even_words', 'gpt4']},\n",
      " {'input': 'THE ONLY LIMIT TO OUR REALIZATION OF TOMORROW WILL BE OUR DOUBTS '\n",
      "           'OF TODAY.',\n",
      "  'tags': ['start_the',\n",
      "           'start_cap',\n",
      "           'all_upper',\n",
      "           'sentence',\n",
      "           'even_words',\n",
      "           'gpt4']}]\n"
     ]
    }
   ],
   "source": [
    "pprint(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input': 'the quick brown fox jumps over the lazy dog.',\n",
      "  'tags': ['shared_sample',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'start_the',\n",
      "           'all_lower',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'today is a beautiful day.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'i love to travel and explore new places.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'python is a popular programming language.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4',\n",
      "           'proper_noun']},\n",
      " {'input': 'the sun sets in the west.',\n",
      "  'tags': ['shared_sample',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'start_the',\n",
      "           'all_lower',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'happiness is a warm cup of tea.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'the moonlight casts a glow over the night.',\n",
      "  'tags': ['shared_sample',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'start_the',\n",
      "           'all_lower',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'winter brings snow and frosty mornings.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'music has the power to evoke strong emotions.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'science and technology are driving innovation.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'friendship is like a shining star in the dark.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'the ocean waves crash against the shore.',\n",
      "  'tags': ['shared_sample',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'start_the',\n",
      "           'all_lower',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'reading opens doors to new worlds.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'coffee is the fuel of productivity.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'dream big and work hard to achieve it.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'the earth rotates on its axis.',\n",
      "  'tags': ['shared_sample',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'start_the',\n",
      "           'all_lower',\n",
      "           'start_lower',\n",
      "           'gpt4',\n",
      "           'proper_noun']},\n",
      " {'input': 'success is a journey, not a destination.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'healthy habits lead to a happy life.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'the stars twinkle in the night sky.',\n",
      "  'tags': ['shared_sample',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'start_the',\n",
      "           'all_lower',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'always strive for excellence.',\n",
      "  'tags': ['all_lower',\n",
      "           'shared_sample',\n",
      "           'sentence',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'the mountains are majestic and grand.',\n",
      "  'tags': ['shared_sample',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'start_the',\n",
      "           'all_lower',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'a brown cat sleeps on the windowsill.',\n",
      "  'tags': ['all_lower', 'sentence', 'odd_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'rainy days are perfect for cozy reading.',\n",
      "  'tags': ['all_lower', 'sentence', 'odd_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'i enjoy hiking in the peaceful woods.',\n",
      "  'tags': ['all_lower',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'java is widely used in enterprise applications.',\n",
      "  'tags': ['all_lower',\n",
      "           'sentence',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4',\n",
      "           'proper_noun']},\n",
      " {'input': 'the wind gently rustles the leaves.',\n",
      "  'tags': ['start_the',\n",
      "           'all_lower',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'yoga and meditation promote inner peace.',\n",
      "  'tags': ['all_lower', 'sentence', 'even_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'candles create a warm and inviting atmosphere.',\n",
      "  'tags': ['all_lower', 'sentence', 'odd_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'summer evenings are filled with laughter.',\n",
      "  'tags': ['all_lower', 'sentence', 'even_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'solving puzzles sharpens the mind.',\n",
      "  'tags': ['all_lower', 'sentence', 'odd_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'bicycling is a great way to stay active.',\n",
      "  'tags': ['all_lower', 'sentence', 'even_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'sunflowers turn to face the sun.',\n",
      "  'tags': ['all_lower',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'the river flows silently through the valley.',\n",
      "  'tags': ['start_the',\n",
      "           'all_lower',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'learning a new language is a rewarding experience.',\n",
      "  'tags': ['all_lower', 'sentence', 'even_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'green tea has many health benefits.',\n",
      "  'tags': ['all_lower', 'sentence', 'even_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'creativity knows no bounds.',\n",
      "  'tags': ['all_lower', 'sentence', 'even_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'the world is full of fascinating cultures.',\n",
      "  'tags': ['start_the',\n",
      "           'all_lower',\n",
      "           'sentence',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'mediterranean cuisine is delicious and healthy.',\n",
      "  'tags': ['all_lower', 'sentence', 'even_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'butterflies dance in the garden.',\n",
      "  'tags': ['all_lower',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'the city comes alive at night.',\n",
      "  'tags': ['start_the',\n",
      "           'all_lower',\n",
      "           'sentence',\n",
      "           'even_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'practicing gratitude leads to a positive mindset.',\n",
      "  'tags': ['all_lower', 'sentence', 'odd_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'oceans hide countless wonders beneath the surface.',\n",
      "  'tags': ['all_lower',\n",
      "           'sentence',\n",
      "           'nature',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4']},\n",
      " {'input': 'writing allows thoughts to come to life.',\n",
      "  'tags': ['all_lower', 'sentence', 'odd_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'a hot cup of cocoa warms the soul.',\n",
      "  'tags': ['all_lower', 'sentence', 'even_words', 'start_lower', 'gpt4']},\n",
      " {'input': \"traveling broadens one's perspective.\",\n",
      "  'tags': ['all_lower', 'sentence', 'even_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'mindfulness brings focus to the present moment.',\n",
      "  'tags': ['all_lower', 'sentence', 'odd_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'simplicity is the ultimate sophistication.',\n",
      "  'tags': ['all_lower', 'sentence', 'odd_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'laughter is contagious and brings joy.',\n",
      "  'tags': ['all_lower', 'sentence', 'even_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'gardening is a therapeutic outdoor activity.',\n",
      "  'tags': ['all_lower', 'sentence', 'even_words', 'start_lower', 'gpt4']},\n",
      " {'input': 'the aroma of fresh bread is irresistible.',\n",
      "  'tags': ['start_the',\n",
      "           'all_lower',\n",
      "           'sentence',\n",
      "           'odd_words',\n",
      "           'start_lower',\n",
      "           'gpt4']}]\n"
     ]
    }
   ],
   "source": [
    "pprint(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_range = list(range(1, 21))\n",
    "\n",
    "def generate_sample(f_condition):\n",
    "    string_len = random.choice(length_range)\n",
    "    output_string = \"\"\n",
    "    while len(output_string.split()) < string_len:\n",
    "        sample = random.choice(words)\n",
    "        if f_condition(sample):\n",
    "            output_string += \" \" + sample\n",
    "        output_string = output_string.strip()\n",
    "    return output_string\n",
    "\n",
    "def append_example(prompt, f_cond_true, n=1):\n",
    "    f_cond_false = lambda x: not f_cond_true(x)\n",
    "    for _ in range(n):\n",
    "        sample_true = generate_sample(f_cond_true)\n",
    "        sample_false = generate_sample(f_cond_false)\n",
    "        prompt += f\"\\nInput: \\\"{sample_true}\\\"\\nLabel: True\\n\"\n",
    "        prompt += f\"\\nInput: \\\"{sample_false}\\\"\\nLabel: False\\n\"\n",
    "    return prompt\n",
    "\n",
    "def gen_user_query(f_cond_true, n=1):\n",
    "    f_cond_false = lambda x: not f_cond_true(x)\n",
    "    labels = []\n",
    "    output_string = \"\"\n",
    "    for _ in range(n):\n",
    "        labels.append(random.choice([True, False]))\n",
    "        sample = generate_sample(f_cond_true if labels[-1] else f_cond_false)\n",
    "        output_string += f\"\\nInput: \\\"{sample}\\\"\\nLabel:\\n\"\n",
    "    return output_string, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m test_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124mBelow are examples from a string classification task.\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mYou will be asked by the user to classify new input strings along with other queries pertaining to the classification task.\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124mEach input is classified as either True or False according to a rule that can be stated simply in natural language.\u001b[39m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mappend_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m system_prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124mWhen responding to user queries, you should respond in the format above, with the input string in quotes and the label as either True or False.\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(system_prompt)\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36mappend_example\u001b[0;34m(prompt, f_cond_true, n)\u001b[0m\n\u001b[1;32m     14\u001b[0m f_cond_false \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;129;01mnot\u001b[39;00m f_cond_true(x)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m---> 16\u001b[0m     sample_true \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_cond_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     sample_false \u001b[38;5;241m=\u001b[39m generate_sample(f_cond_false)\n\u001b[1;32m     18\u001b[0m     prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInput: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msample_true\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLabel: True\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mgenerate_sample\u001b[0;34m(f_condition)\u001b[0m\n\u001b[1;32m      5\u001b[0m output_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_string\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;241m<\u001b[39m string_len:\n\u001b[0;32m----> 7\u001b[0m     sample \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[43mwords\u001b[49m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f_condition(sample):\n\u001b[1;32m      9\u001b[0m         output_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m sample\n",
      "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "file_name = \"random_even_letter.txt\"\n",
    "rule_name = \"Random String: Even Number of Letters\"\n",
    "\n",
    "def write_header(x):\n",
    "    line_delim = [\"=\"] * 79\n",
    "    line_delim = \"\".join(line_delim)\n",
    "    return f\"{line_delim}\\n{x}\\n{line_delim}\\n\"\n",
    "\n",
    "rule = \"The input string has word of even length.\"\n",
    "test_true = lambda x: len(x) % 2 == 0\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Below are examples from a string classification task.\n",
    "You will be asked by the user to classify new input strings along with other queries pertaining to the classification task.\n",
    "Each input is classified as either True or False according to a rule that can be stated simply in natural language.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = append_example(system_prompt, test_true, n=10)\n",
    "\n",
    "system_prompt += \"\"\"\n",
    "When responding to user queries, you should respond in the format above, with the input string in quotes and the label as either True or False.\n",
    "\"\"\"\n",
    "\n",
    "print(system_prompt)\n",
    "\n",
    "with open(results_path / file_name, \"w\") as f:\n",
    "    f.write(write_header(rule_name))\n",
    "    f.write(f\"\\nRULE: {rule}\\n\\n\")\n",
    "\n",
    "with open(results_path / file_name, \"a\") as f:\n",
    "    f.write(write_header(\"SYSTEM PROMPT\"))\n",
    "    f.write(system_prompt)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(write_header(\"RESULTS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_prediction(system_prompt, user_query, model=\"gpt-4\"):\n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_query\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=len(system_prompt),\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    "  )\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \"splenunculus aistopod preday compulsative\"\n",
      "Label: True\n",
      "\n",
      "Input: \"nephrotoxicity remantle yields dhai semiaxis colourableness wooliest sororize amylogenic examiner gour disparages compenetrate shattering\"\n",
      "Label: False\n",
      "\n",
      "Input: \"bachelorette embace wordbook hollowed wittolly endosiphonal oversolidified hydrothermal degenerative\"\n",
      "Label: True\n",
      "\n",
      "Input: \"unsuperfluousness monsoon chrysanisic sheerly bibbled byblidaceae bimasty curiosity avenses\"\n",
      "Label: False\n",
      "\n",
      "Input: \"unconvertible successlessly pulchritude sulphurated ingates unhorny dynodes polyaffectioned immortalising lemogra veering recharged arousal topsy preadvise myoinositol phymatoid tepache\"\n",
      "Label: False\n",
      "\n",
      "Input: \"aguacateca trophodisc sociocentric hypothecater unappreciatively lamnidae negligibleness misleading endaze inscript expediteness misenite fluorotype merrytrotter legend camerine despised samucu stainabilities lurching\"\n",
      "Label: False\n",
      "\n",
      "Input: \"chesses unslacked sab cooja soaringly pococurantism photochronography impoverishing squet wagtail quantometer tonsbergite solicitations convulsions parathyroidectomizing inherencies doodlebug proteases\"\n",
      "Label: False\n",
      "\n",
      "Input: \"understandable stuffiness tentamen pioury flowerer overstay poltroon outgamed apollonian besmooth spittlemen debilities calycozoan bienne pterylographical outsings wicopy\"\n",
      "Label: False\n",
      "\n",
      "Input: \"sigmas\"\n",
      "Label: True\n",
      "\n",
      "Input: \"frakturs sulfatic confoundedly assimulate\"\n",
      "Label: True\n"
     ]
    }
   ],
   "source": [
    "output_string, labels = gen_user_query(test_true, n=10)\n",
    "user_query = output_string\n",
    "print(gpt_prediction(system_prompt, user_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, False, False, True, False, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Input: \"oogamies fluorboric zees lemography waggoned meow slaver sandmite stroky expression unrummaged episodes archaeologic cheeringly unsturdily victrola tyrannidae discophore\"\n",
      "Label: True\n",
      "MODEL: False\n",
      "\n",
      "Input: \"everlasting protuberate\"\n",
      "Label: False\n",
      "MODEL: True\n",
      "\n",
      "Input: \"garrulinae anogenital\"\n",
      "Label: True\n",
      "MODEL: True\n",
      "\n",
      "Input: \"predissolve phosphomolybdic crotons woodchats\"\n",
      "Label: False\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-AyNKjYMIA668Sc8nezuCmdTx on tokens per min (TPM): Limit 40000, Used 37277, Requested 3761. Please try again in 1.557s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLabel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLabel:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODEL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mgpt_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[118], line 2\u001b[0m, in \u001b[0;36mgpt_prediction\u001b[0;34m(system_prompt, user_query, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgpt_prediction\u001b[39m(system_prompt, user_query, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_query\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/classification-faithfulness/.venv/lib/python3.10/site-packages/openai/_utils/_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/classification-faithfulness/.venv/lib/python3.10/site-packages/openai/resources/chat/completions.py:598\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/classification-faithfulness/.venv/lib/python3.10/site-packages/openai/_base_client.py:1063\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1051\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1059\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1060\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1061\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1062\u001b[0m     )\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/classification-faithfulness/.venv/lib/python3.10/site-packages/openai/_base_client.py:842\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    835\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    841\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/classification-faithfulness/.venv/lib/python3.10/site-packages/openai/_base_client.py:873\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m--> 873\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/classification-faithfulness/.venv/lib/python3.10/site-packages/openai/_base_client.py:933\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    931\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/classification-faithfulness/.venv/lib/python3.10/site-packages/openai/_base_client.py:873\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m--> 873\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/classification-faithfulness/.venv/lib/python3.10/site-packages/openai/_base_client.py:933\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    931\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/classification-faithfulness/.venv/lib/python3.10/site-packages/openai/_base_client.py:885\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-AyNKjYMIA668Sc8nezuCmdTx on tokens per min (TPM): Limit 40000, Used 37277, Requested 3761. Please try again in 1.557s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "split_query = user_query.split(\"\\n\")\n",
    "queries = [split_query[i] for i in range(len(split_query)) if i % 3 == 1]\n",
    "print(len(queries))\n",
    "for label, query in zip(labels, queries):\n",
    "    print(f\"{query}\\nLabel: {label}\")\n",
    "    query = f\"{query}\\nLabel:\"\n",
    "    print(f\"MODEL: {gpt_prediction(system_prompt, query)}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
